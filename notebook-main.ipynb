{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb520aec-d996-4a06-a02a-5aae10afaaa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "###Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a9de14-da90-4df4-828a-82720e2f4b99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#python list to dataframe\n",
    "\n",
    "data = [\n",
    "    (\"Alice\", 1, \"New York\"),\n",
    "    (\"Bob\", 2, \"London\"),\n",
    "    (\"Charlie\", 3, \"Paris\")\n",
    "]\n",
    "\n",
    "df=spark.createDataFrame(data,[\"Name\", \"ID\", \"City\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52d3f22a-c1fe-4a2d-a5bb-1579feb5b9e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#loading csv data\n",
    "\n",
    "df=spark.read.csv(\"/FileStore/tables/BigMart_Sales.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9e650e06-e91a-45c6-a848-2154cdfa975c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.printSchema()\n",
    "# df.show()\n",
    "df.limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43cb806e-15de-400b-b164-83104ba6a47e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3da37a37-5756-41c7-abd1-69334dfd09c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ddl schema\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "my_ddl_schema= \"\"\"\n",
    "                    Item_Identifier STRING,\n",
    "                    Item_Weight DOUBLE,\n",
    "                    Item_Fat_Content STRING,\n",
    "                    Item_Visibility DOUBLE,\n",
    "                    Item_Type STRING,\n",
    "                    Item_MRP DOUBLE,\n",
    "                    Outlet_Identifier STRING,\n",
    "                    Outlet_Establishment_Year INT,\n",
    "                    Outlet_Size STRING,\n",
    "                    Outlet_Location_Type STRING,\n",
    "                    Outlet_Type STRING,\n",
    "                    Item_Outlet_Sales DOUBLE\n",
    "                \"\"\"\n",
    "\n",
    "#schema defined using structType\n",
    "my_struct_schema=StructType([\n",
    "    StructField(\"Item_Identifier\", StringType(), True),\n",
    "    StructField(\"Item_Weight\", DoubleType(), True),\n",
    "    StructField(\"Item_Fat_Content\", StringType(), True),\n",
    "    StructField(\"Item_Visibility\", DoubleType(), True),\n",
    "    StructField(\"Item_Type\", StringType(), True),\n",
    "    StructField(\"Item_MRP\", DoubleType(), True),\n",
    "    StructField(\"Outlet_Identifier\", StringType(), True),\n",
    "    StructField(\"Outlet_Establishment_Year\", IntegerType(), True),\n",
    "    StructField(\"Outlet_Size\", StringType(), True),\n",
    "    StructField(\"Outlet_Location_Type\", StringType(), True),\n",
    "    StructField(\"Outlet_Type\", StringType(), True),\n",
    "    StructField(\"Item_Outlet_Sales\", DoubleType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dbab599-2bb8-434b-a375-c0c4142d57a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"/FileStore/tables/BigMart_Sales.csv\", header=True, schema=my_struct_schema)\n",
    "df.printSchema()\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5c2782f-4b54-44c0-ac8b-a9ecd8985c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Column Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b563ca40-4c5f-4f83-b6e8-098acc36173c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Column Operations\n",
    "\n",
    "#select\n",
    "df.select(\"Item_Identifier\").limit(5).display()\n",
    "\n",
    "#alias\n",
    "df.select(col(\"Item_Identifier\").alias(\"Item_ID\"),col(\"Item_Weight\"),col(\"Item_Fat_Content\")).limit(5).display()\n",
    "\n",
    "#withColumn\n",
    "df_with_temp = df.withColumn(\"temp\", F.col(\"Item_Weight\") + 2)\n",
    "\n",
    "#withColumnRenamed\n",
    "df_renamed = df_with_temp.withColumnRenamed(\"temp\", \"temp_column\")\n",
    "display(df_renamed.limit(5))\n",
    "\n",
    "#drop column\n",
    "df_renamed.drop(\"temp_column\").limit(5).display()\n",
    "\n",
    "#type casting\n",
    "df.withColumn(\"Item_Weight\",col(\"Item_Weight\").cast(StringType())).limit(5).display()\n",
    "\n",
    "#replacing values\n",
    "df.withColumn(\"Item_Visibility\",F.round(F.col(\"Item_Visibility\"),2)).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e150d16e-e513-4b86-b326-e00a48a359be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Row Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06c4e909-cbea-4a27-bb44-64c4524e9de2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# row operations\n",
    "\n",
    "#Filter\n",
    "df.filter(col(\"Item_Fat_Content\") == \"Regular\").limit(5).display()\n",
    "df.filter((col(\"Item_Type\") == \"Soft Drinks\") & (col(\"Item_Weight\") > 5)).limit(5).display()\n",
    "df.filter(\n",
    "    (col(\"Outlet_Location_Type\").isin(\"Tier 1\", \"Tier 2\"))\n",
    "    & (col(\"Outlet_Size\").isNull())\n",
    ").limit(5).display()\n",
    "\n",
    "#distinct\n",
    "df.distinct().limit(5).display()\n",
    "\n",
    "#sort\n",
    "df.sort(col(\"Item_Weight\").desc()).limit(5).display()\n",
    "df.sort([col(\"Item_Weight\"),col(\"Item_MRP\")],ascending=[0,0]).limit(5).display()\n",
    "\n",
    "#drop duplicates\n",
    "df.dropDuplicates().display()\n",
    "df.dropDuplicates(subset=[\"Item_Type\"]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94f63fef-1ec6-43e5-956b-6fb743cad334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf173235-6780-40d1-8944-fd05cc07dee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Union\n",
    "\n",
    "df1_data = [(\"Apple\", 100), (\"Banana\", 150)]\n",
    "df1_schema = StructType([\n",
    "    StructField(\"item\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True)\n",
    "])\n",
    "df1 = spark.createDataFrame(df1_data, schema=df1_schema)\n",
    "\n",
    "# df1.display()\n",
    "\n",
    "df2_data = [(\"Orange\", 200), (\"Apple\", 120)]\n",
    "df2_schema = StructType([\n",
    "    StructField(\"item\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True)\n",
    "])\n",
    "df2 = spark.createDataFrame(df2_data, schema=df2_schema)\n",
    "\n",
    "df3_data = [(50, \"Grape\")]\n",
    "df3_schema = StructType([\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"item\", StringType(), True) # Order is different from df1 and df2\n",
    "])\n",
    "df3 = spark.createDataFrame(df3_data, schema=df3_schema)\n",
    "\n",
    "# df2.display()\n",
    "\n",
    "df1.union(df2).display()\n",
    "df1.unionByName(df2).unionByName(df3).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c83e50ce-e1a1-46c5-beb8-2b5fc6e56cda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Date Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68aee8e2-7be7-4309-bd36-962527180ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, date_add, date_sub, datediff, date_format\n",
    "\n",
    "#Date Functions\n",
    "\n",
    "#current date\n",
    "df.withColumn(\"current_date\",current_date()).limit(1).display()\n",
    "\n",
    "#date add\n",
    "df.withColumn(\"week_after\",date_add(\"current_date\",7)).limit(1).display()\n",
    "\n",
    "#date sub\n",
    "df_with_week_before=df.withColumn(\"week_before\",date_sub(\"current_date\",7))\n",
    "# df_with_week_before=df.withColumn(\"week_after\",date_add(\"current_date\",-7)).limit(1).display()\n",
    "df_with_week_before.limit(1).display()\n",
    "\n",
    "#date diff\n",
    "df_with_week_before.withColumn(\"diff_between_days\",datediff(\"current_date\",\"week_before\")).limit(1).display()\n",
    "\n",
    "#date format\n",
    "df_with_week_before.withColumn(\"week_before\",date_format(\"week_before\",\"dd/MM/yyyy\")).limit(1).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cf2d3c7-9b46-4f16-9249-6b3b563cb0a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Handing null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc678c4-5289-432d-b7a2-4b0145c22384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#droping records having null\n",
    "\n",
    "df.dropna(\"all\") # drop the record if all column have null value in that record\n",
    "df.dropna(\"any\").display() #drop every record where any of the column have the null value\n",
    "df.dropna(subset=[\"Outlet_Size\"]).display() # search for the null in the specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab031893-649b-4231-8c90-0da3aaf1b965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filling null values\n",
    "\n",
    "df.fillna(\"NA\").display() # apply to all null\n",
    "df.fillna({\"Item_Weight\":-1,\"Outlet_size\":\"NA\"}).display() #apply with specific value\n",
    "\n",
    "df.fillna(\"NOT\", subset=[\"Outlet_Size\"]).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e61dff14-bac2-4f23-94d6-5044a7872edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Splitting and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d9fb407-0369-4ba0-a13b-0ce36f3e5557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split,array_contains\n",
    "\n",
    "df_with_splitted_text=df.withColumn(\"Outlet_Type\",split(\"Outlet_Type\",\" \")) # splitting based on a delimiter\n",
    "df.withColumn(\"Outlet_Type\",split(\"Outlet_Type\",\" \")[1]).display() #indexing\n",
    "\n",
    "#array contains\n",
    "df_with_splitted_text.withColumn(\"Type1_flag\",array_contains(\"Outlet_Type\",\"Type1\")).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a70037dc-0f54-4ee1-8524-c7f17d34b084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e0a503-cc3b-4935-ba8c-fbf514f2c6bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,min,max,count, collect_list, collect_set\n",
    "\n",
    "df.groupBy(\"Item_Type\").agg(count(\"Item_MRP\")).display()\n",
    "\n",
    "df.groupBy(\"Item_Type\",\"Outlet_Size\").agg(avg(\"Item_MRP\")).alias(\"avg price by outlet size\").display()#group by on two columns\n",
    "\n",
    "df.groupBy(\"Item_Type\",\"Outlet_Size\").agg(sum(\"Item_MRP\"),avg(\"Item_MRP\")).display() #group by on two column and two agg function\n",
    "\n",
    "df.groupBy(\"Item_Type\").agg(collect_list(\"Item_Identifier\")).display()\n",
    "df.groupBy(\"Item_Type\").agg(collect_set(\"Item_Identifier\")).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19fd9153-a93f-433f-8585-1eaabcca7842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6197b715-03d7-4745-aef1-515db2bfe814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"Item_Type\").pivot(\"Outlet_Size\").agg(avg(\"Item_MRP\")).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e90d3232-c468-4141-b956-f47266148e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### When Otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79a16134-2f42-4aa2-9475-65df2f43ff68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_with_veg_column=df.withColumn(\"isVeg\",when(col(\"Item_Type\")==\"Meat\",False).otherwise(True))\n",
    "df_with_veg_column.select(\"Item_Type\",\"isVeg\").limit(5).display()\n",
    "\n",
    "df_with_veg_column.withColumn(\"expensive_flag\",when((col(\"isVeg\")==True) & (col(\"Item_MRP\")>=100),\"Veg Expensive\")\\\n",
    "                            .when((col(\"isVeg\")==True) & (col(\"Item_MRP\")<100),\"Veg inExpensive\")\\\n",
    "                            .when((col(\"isVeg\")==False) & (col(\"Item_MRP\")>=100),\"Non Veg Expensive\")\\\n",
    "                            .otherwise(\"Non-Veg InExpensive\")).select(\"Item_Type\",\"Item_MRP\",\"isVeg\",\"expensive_flag\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a58bbcbb-b28a-4a10-9028-254a04c3581c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba2c9ce-3625-4e75-98e6-06048cb2b7d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_data = [\n",
    "    (1, \"Alice\", 101),\n",
    "    (2, \"Bob\", 102),\n",
    "    (3, \"Charlie\", 101),\n",
    "    (4, \"David\", 103),\n",
    "    (5, \"Eve\", None)\n",
    "]\n",
    "emp_schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),\n",
    "    StructField(\"emp_name\", StringType(), True),\n",
    "    StructField(\"dept_id\", IntegerType(), True)\n",
    "])\n",
    "df_emp = spark.createDataFrame(emp_data, schema=emp_schema)\n",
    "df_emp.display()\n",
    "\n",
    "dept_data = [\n",
    "    (101, \"Sales\", \"New York\"),\n",
    "    (102, \"Marketing\", \"London\"),\n",
    "    (103, \"IT\", \"Paris\"),\n",
    "    (104, \"HR\", \"Remote\")\n",
    "]\n",
    "dept_schema = StructType([\n",
    "    StructField(\"dept_id\", IntegerType(), True),\n",
    "    StructField(\"dept_name\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True)\n",
    "])\n",
    "df_dept = spark.createDataFrame(dept_data, schema=dept_schema)\n",
    "df_dept.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "750ee016-5dfe-4ede-9538-c4be0704ca03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#inner\n",
    "df_emp.join(df_dept,df_emp[\"dept_id\"]==df_dept[\"dept_id\"],\"inner\").display()\n",
    "\n",
    "#left\n",
    "df_emp.join(df_dept,df_emp[\"dept_id\"]==df_dept[\"dept_id\"],\"left\").display()\n",
    "\n",
    "#right\n",
    "df_emp.join(df_dept,df_emp[\"dept_id\"]==df_dept[\"dept_id\"],\"right\").display()\n",
    "\n",
    "#full\n",
    "df_emp.join(df_dept,df_emp[\"dept_id\"]==df_dept[\"dept_id\"],\"full\").display()\n",
    "\n",
    "#anti\n",
    "df_emp.join(df_dept,df_emp[\"dept_id\"]==df_dept[\"dept_id\"],\"anti\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc961888-c80b-4959-b97e-0053912275b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fed2827-f70e-4930-b791-5b5e705fbe05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import row_number, rank, dense_rank\n",
    "\n",
    "df.withColumn(\"row_number\",row_number().over(Window.orderBy(\"Item_Identifier\")))\\\n",
    "    .withColumn(\"rank\",rank().over(Window.orderBy(\"Item_Identifier\")))\\\n",
    "        .withColumn(\"dense_rank\",dense_rank().over(Window.orderBy(\"Item_Identifier\"))).limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "109f1d9d-8b5e-4b1a-a0f9-38bb489e645e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#Running total\n",
    "\n",
    "df.withColumn(\"cummulative_sum\",sum(\"Item_MRP\").over(Window.orderBy(\"Item_Type\").partitionBy(\"Item_Type\").rowsBetween(Window.unboundedPreceding,Window.currentRow))).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5107ba40-eae3-4e93-8ef0-cafbb4c36f87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cda25280-58f0-4319-accd-bd75c8e48484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    if x is None:\n",
    "        return \"NA\"\n",
    "    if x > 10:\n",
    "        return \"Heavy\"\n",
    "    return \"Light\"\n",
    "\n",
    "my_udf=udf(my_func)\n",
    "\n",
    "df.withColumn(\"weight_flag\",my_udf(\"Item_Weight\")).limit(5).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9768d0eb-bac9-4c25-b2df-f7531e7498b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "742e4256-6783-44b8-82d8-8e68f3cc77b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#modes : append, overwrite, error, ignore\n",
    "\n",
    "df.write.format(\"csv\").mode(\"ignore\").save(\"/FileStore/tables/csv/my-file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785abaf6-faec-4a37-a9e7-5fbc43db14aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/csv/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7baa171-0be9-45af-af74-8e7e2697f1c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e35db07-acbb-48cd-b17d-08a91c8b2f3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#creating temp view from df\n",
    "df.createTempView(\"view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29220943-88b5-415b-82ec-f61f6a4fd95d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from view where Item_Weight >10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d09a580-d98e-4f97-8ffd-422318eebd65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# writing sql and convert back into df\n",
    "df_sql=spark.sql(\"select * from view\")\n",
    "df_sql.limit(5).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4054406389787223,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "notebook-main",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}